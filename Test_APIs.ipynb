{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpTex7FAI9sdy5NFmwbXWF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weagan/Tools/blob/main/Test_APIs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "888863dc",
        "outputId": "4a2d2a9a-4f34-4a1a-e4bf-69496ab92756"
      },
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install -q cohere"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.0/319.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5a0dd93",
        "outputId": "2d144dde-b662-465c-d4a7-8c5f88500500"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "import cohere\n",
        "\n",
        "# Retrieve the API key from Colab secrets\n",
        "try:\n",
        "    COHERE_API_KEY = userdata.get('COHERE_API_KEY')\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"COHERE_API_KEY not found in Colab secrets. Please set it.\")\n",
        "    COHERE_API_KEY = None\n",
        "\n",
        "if COHERE_API_KEY:\n",
        "    try:\n",
        "        # Initialize the Cohere client\n",
        "        co = cohere.Client(COHERE_API_KEY)\n",
        "\n",
        "        # Make a simple API call to test access using the Chat API.\n",
        "        # IMPORTANT: Replace '<YOUR_VALID_COHERE_MODEL_NAME>' with a currently supported model\n",
        "        # You can find valid models in Cohere's documentation: https://docs.cohere.com/docs/models#command\n",
        "        response = co.chat(\n",
        "            message='Hello, Cohere',\n",
        "            model='command-a-03-2025', # Placeholder: Please replace with a currently supported model from Cohere's documentation\n",
        "            max_tokens=10\n",
        "        )\n",
        "\n",
        "        print(\"Successfully accessed Cohere API!\")\n",
        "        print(f\"Response from Cohere: {response.text}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to access Cohere API. Error: {e}\")\n",
        "else:\n",
        "    print(\"API key is not set, cannot test access.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed Cohere API!\n",
            "Response from Cohere: Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "740226af"
      },
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install -q openai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "494a45a9",
        "outputId": "dd44a7e5-0df6-4792-ae0d-370dc50d88ff"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "# Retrieve the API key from Colab secrets\n",
        "try:\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"OPENAI_API_KEY not found in Colab secrets. Please set it.\")\n",
        "    OPENAI_API_KEY = None\n",
        "\n",
        "if OPENAI_API_KEY:\n",
        "    try:\n",
        "        # Initialize the OpenAI client\n",
        "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "        # Make a simple API call to test access (e.g., list models)\n",
        "        # Note: Listing models requires an API key but doesn't consume credits for chat/completions.\n",
        "        # If you prefer a chat completion, you can use client.chat.completions.create\n",
        "        # with a valid model like 'gpt-3.5-turbo'.\n",
        "        models = client.models.list()\n",
        "\n",
        "        print(\"Successfully accessed OpenAI API!\")\n",
        "        print(f\"First 5 models: {[model.id for model in models.data[:5]]}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to access OpenAI API. Error: {e}\")\n",
        "else:\n",
        "    print(\"API key is not set, cannot test access.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed OpenAI API!\n",
            "First 5 models: ['gpt-3.5-turbo', 'gpt-5.2-codex', 'gpt-4o-mini-tts-2025-12-15', 'gpt-realtime-mini-2025-12-15', 'gpt-audio-mini-2025-12-15']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8558ed4a",
        "outputId": "565e7e38-7601-404c-aacc-1619812cd2a8"
      },
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve the API key from Colab secrets\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "if OPENAI_API_KEY:\n",
        "    try:\n",
        "        # Initialize the OpenAI client\n",
        "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "        # Send a simple chat completion prompt to gpt-3.5-turbo\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Print the model's response\n",
        "        print(f\"Model: {response.model}\")\n",
        "        print(f\"Response: {response.choices[0].message.content}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to get response from OpenAI API. Error: {e}\")\n",
        "else:\n",
        "    print(\"API key is not set, cannot make API calls.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to get response from OpenAI API. Error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca24420c",
        "outputId": "28030f50-1200-448b-e25e-1758ecd4ef73"
      },
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install -q groq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/138.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m133.1/138.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc256da2",
        "outputId": "743d4b08-5df0-42c9-9449-c15007abc7f7"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from groq import Groq\n",
        "\n",
        "# Retrieve the API key from Colab secrets\n",
        "try:\n",
        "    GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"GROQ_API_KEY not found in Colab secrets. Please set it.\")\n",
        "    GROQ_API_KEY = None\n",
        "\n",
        "if GROQ_API_KEY:\n",
        "    try:\n",
        "        # Initialize the Groq client\n",
        "        client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "        # Make a simple chat completion API call\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": \"Explain the importance of low-latency AI inference.\",\n",
        "                }\n",
        "            ],\n",
        "            model=\"llama-3.1-8b-instant\", # Placeholder: Please replace with a currently supported model from Groq's documentation\n",
        "            max_tokens=100\n",
        "        )\n",
        "\n",
        "        print(\"Successfully accessed Groq API!\")\n",
        "        print(f\"Response from Groq: {chat_completion.choices[0].message.content}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to access Groq API. Error: {e}\")\n",
        "else:\n",
        "    print(\"API key is not set, cannot test access.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully accessed Groq API!\n",
            "Response from Groq: Low-latency AI inference is crucial in various applications that require prompt decision-making, real-time processing, and high-accuracy predictions. The importance of low-latency AI inference lies in its ability to ensure seamless integration with systems and environments where speed and timeliness are critical factors.\n",
            "\n",
            "**Key Importance Points:**\n",
            "\n",
            "1. **Real-Time Decision-Making**: In applications such as finance, trading, and autonomous vehicles, low-latency AI inference enables faster decision-making, which can lead to better outcomes and increased\n"
          ]
        }
      ]
    }
  ]
}