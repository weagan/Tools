{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weagan/Tools/blob/main/Multilingual_Microsoft_Edge_TTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2a55ea5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ee79147-ec08-4fb3-a10b-88aa8a5cf93f"
      },
      "source": [
        "!pip install -q edge-tts pyarabic gradio-client pydub nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/126.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "import edge_tts\n",
        "from gradio_client import Client\n",
        "import pyarabic.araby as araby\n",
        "import asyncio\n",
        "from pydub import AudioSegment\n",
        "import nltk\n",
        "import gradio as gr\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "4659e7ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c178914-7e87-42df-b8a2-8f72ae83890c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\\('\n",
            "  m = re.match('([su]([0-9]{1,2})p?) \\(([0-9]{1,2}) bit\\)$', token)\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\\('\n",
            "  m2 = re.match('([su]([0-9]{1,2})p?)( \\(default\\))?$', token)\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\\('\n",
            "  elif re.match('(flt)p?( \\(default\\))?$', token):\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\\('\n",
            "  elif re.match('(dbl)p?( \\(default\\))?$', token):\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22a006a3"
      },
      "source": [
        "# Language and voice mapping dictionary\n",
        "language_dict = {\n",
        "  \"English\": {\n",
        "    \"Jenny\": \"en-US-JennyNeural\",\n",
        "    \"Guy\": \"en-US-GuyNeural\"\n",
        "  },\n",
        "  \"Arabic\": {\n",
        "    \"Hamed\": \"ar-SA-HamedNeural\",\n",
        "    \"Fatima\": \"ar-AE-FatimaNeural\"\n",
        "  },\n",
        "  \"Irish\": {\n",
        "    \"Colm\": \"ga-IE-ColmNeural\",\n",
        "    \"Orla\": \"ga-IE-OrlaNeural\"\n",
        "  }\n",
        "  # Additional languages can be added here as needed\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "822db8d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dc9a97f-6849-4506-9527-2970f7b9aa08"
      },
      "source": [
        "# Initialize Tashkeel client for Arabic text processing\n",
        "client = Client(\"MohamedRashad/arabic-auto-tashkeel\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded as API: https://mohamedrashad-arabic-auto-tashkeel.hf.space ✔\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0db805c2"
      },
      "source": [
        "async def text_to_speech_edge(text, language_code, speaker, tashkeel_checkbox=False):\n",
        "  \"\"\"Convert text to speech with 5-second pauses between sentences.\"\"\"\n",
        "\n",
        "  # Process Arabic text with Tashkeel if requested\n",
        "  if language_code == \"Arabic\" and tashkeel_checkbox:\n",
        "    text = client.predict(\n",
        "      input_text=araby.strip_diacritics(text),\n",
        "      api_name=\"/infer_shakkala\"\n",
        "    )\n",
        "\n",
        "  # Validate language and speaker selection\n",
        "  if language_code not in language_dict:\n",
        "      raise ValueError(f\"Selected language '{language_code}' is not supported.\")\n",
        "\n",
        "  selected_language_speakers = language_dict[language_code]\n",
        "  if speaker not in selected_language_speakers:\n",
        "      raise ValueError(f\"Speaker '{speaker}' is not available for language '{language_code}'.\")\n",
        "\n",
        "  voice = selected_language_speakers[speaker]\n",
        "\n",
        "  # Split text into sentences\n",
        "  sentences = nltk.sent_tokenize(text)\n",
        "  full_audio = AudioSegment.empty()\n",
        "  silent_segment = AudioSegment.silent(duration=5000)  # 5-second pause\n",
        "\n",
        "  # Generate audio for each sentence\n",
        "  for i, sentence in enumerate(sentences):\n",
        "    communicate = edge_tts.Communicate(sentence, voice)\n",
        "\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as tmp_sentence_file:\n",
        "      tmp_sentence_path = tmp_sentence_file.name\n",
        "      await communicate.save(tmp_sentence_path)\n",
        "\n",
        "    sentence_audio = AudioSegment.from_mp3(tmp_sentence_path)\n",
        "    full_audio += sentence_audio\n",
        "\n",
        "    # Add silence between sentences (not after the last one)\n",
        "    if i < len(sentences) - 1:\n",
        "      full_audio += silent_segment\n",
        "\n",
        "  # Save concatenated audio\n",
        "  with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as tmp_final_file:\n",
        "    tmp_final_path = tmp_final_file.name\n",
        "    full_audio.export(tmp_final_path, format=\"mp3\")\n",
        "\n",
        "  return text, tmp_final_path"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage demonstrating the enhanced functionality\n",
        "async def run_examples():\n",
        "    # English example\n",
        "    print(\"Generating English speech with pauses...\")\n",
        "    english_text = \"Hello, this is a test. This sentence has a pause after it. And this is the third sentence.\"\n",
        "    output_text_en, audio_path_en = await text_to_speech_edge(english_text, \"English\", \"Jenny\")\n",
        "    print(f\"English Audio saved to: {audio_path_en}\")\n",
        "\n",
        "    # Arabic example with Tashkeel\n",
        "    print(\"\\nGenerating Arabic speech with Tashkeel and pauses...\")\n",
        "    arabic_text = \"السلام عليكم ورحمة الله وبركاته. كيف حالك اليوم؟ أتمنى لك يوما سعيدا.\"\n",
        "    output_text_ar, audio_path_ar = await text_to_speech_edge(arabic_text, \"Arabic\", \"Hamed\", True)\n",
        "    print(f\"Arabic Audio saved to: {audio_path_ar}\")\n",
        "\n",
        "    # Irish example\n",
        "    print(\"\\nGenerating Irish speech with pauses...\")\n",
        "    irish_text = \"Amárach beidh sé fliuch. Bhí mé sa bhaile inné.\"\n",
        "    output_text_ir, audio_path_ir = await text_to_speech_edge(irish_text, \"Irish\", \"Colm\")\n",
        "    print(f\"Irish Audio saved to: {audio_path_ir}\")\n",
        "\n",
        "# Run the examples\n",
        "await run_examples()"
      ],
      "metadata": {
        "id": "1329742c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d87f42a-6801-4f6e-a90e-fe2f4dc56f0b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating English speech with pauses...\n",
            "English Audio saved to: /tmp/tmp5i6o3i9m.mp3\n",
            "\n",
            "Generating Arabic speech with Tashkeel and pauses...\n",
            "Arabic Audio saved to: /tmp/tmpkruuy74w.mp3\n",
            "\n",
            "Generating Irish speech with pauses...\n",
            "Irish Audio saved to: /tmp/tmp7w3ie5im.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function for dynamic speaker selection\n",
        "def get_speakers_for_language(language):\n",
        "    speakers = list(language_dict.get(language, {}).keys())\n",
        "    if speakers:\n",
        "        return gr.update(choices=speakers, value=speakers[0])\n",
        "    else:\n",
        "        return gr.update(choices=[], value=None)\n",
        "\n",
        "# Initial speaker list for Irish (default)\n",
        "initial_speakers = list(language_dict.get(\"Irish\", {}).keys())"
      ],
      "metadata": {
        "id": "522e86e1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Multilingual TTS with Sentence Pauses\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            text_input = gr.Textbox(label=\"Enter Text\", lines=5,\n",
        "                                    placeholder=\"Type your text here (sentences will have 5-second pauses between them)...\")\n",
        "            language_dropdown = gr.Dropdown(\n",
        "                list(language_dict.keys()), label=\"Select Language\", value=\"Irish\"\n",
        "            )\n",
        "            speaker_dropdown = gr.Dropdown(\n",
        "                choices=initial_speakers, label=\"Select Speaker\",\n",
        "                value=initial_speakers[0] if initial_speakers else None\n",
        "            )\n",
        "            tashkeel_checkbox = gr.Checkbox(label=\"Add Tashkeel (Arabic Only)\", value=False)\n",
        "            generate_button = gr.Button(\"Generate Speech\")\n",
        "\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Processed Text\")\n",
        "            audio_output = gr.Audio(label=\"Generated Speech (with 5s pauses between sentences)\")\n",
        "\n",
        "    # Dynamic speaker update based on language selection\n",
        "    language_dropdown.change(\n",
        "        get_speakers_for_language,\n",
        "        inputs=language_dropdown,\n",
        "        outputs=speaker_dropdown\n",
        "    )\n",
        "\n",
        "    # Connect the TTS function to the interface\n",
        "    generate_button.click(\n",
        "        fn=text_to_speech_edge,\n",
        "        inputs=[text_input, language_dropdown, speaker_dropdown, tashkeel_checkbox],\n",
        "        outputs=[output_text, audio_output]\n",
        "    )\n",
        "\n",
        "demo.launch(debug=True, share=True)"
      ],
      "metadata": {
        "id": "cbc4ab7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "outputId": "7c1949c8-5bc4-4af9-eaf3-fb9db21c049b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://5188d5597597413f5a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5188d5597597413f5a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35a9cc47"
      },
      "source": [
        "## Summary\n",
        "\n",
        "### Modifications Made:\n",
        "1. **Enhanced `text_to_speech_edge` function** to:\n",
        "   - Split input text into sentences using `nltk.sent_tokenize()`\n",
        "   - Generate separate audio for each sentence\n",
        "   - Insert 5-second silent pauses between sentences using `pydub.AudioSegment.silent(duration=5000)`\n",
        "   - Concatenate all audio segments into a final output\n",
        "\n",
        "2. **Dependencies added**:\n",
        "   - `pydub` for audio manipulation\n",
        "   - `nltk` for sentence tokenization\n",
        "   - Required NLTK data (`punkt` and `punkt_tab`) downloaded\n",
        "\n",
        "### Key Features:\n",
        "- **Natural pauses**: 5-second silences between sentences for better listening experience\n",
        "- **Multilingual support**: Works with English, Arabic (with optional Tashkeel), Irish, and other languages\n",
        "- **Dynamic interface**: Gradio UI with language-speaker synchronization\n",
        "- **Error handling**: Validates language and speaker selections\n",
        "\n",
        "### Usage:\n",
        "Call `text_to_speech_edge(text, language, speaker, tashkeel_checkbox)` to generate speech with automatic sentence segmentation and pauses."
      ]
    }
  ]
}